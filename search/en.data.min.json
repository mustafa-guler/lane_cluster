[{"id":0,"href":"/lane_custer/slurm-basics/submitting-jobs/simple-script/","title":"A Simple sbatch Script","parent":"Submitting Jobs","content":"Consider the following shell script.\n#!/bin/bash # contents of example_script.sh  seq 1 10000 | shuf | sort -n This prints numbers from 1 to 10000 (seq), randomly shuffles them (shuf), then attempts to resort them. How could we submit this as a job? The simplest answer is to just execute sbatch with this script as a parameter.\nsbatch -p pool1 -n 1 example_script.sh This will request one task (-n 1) on the pool1 partition (-p pool1) and run our script on it.\nHow can we check the output? By default Slurm will write stdout and stderr to files named after the job ID. This is not useful for us usually because it\u0026rsquo;s unlikely you\u0026rsquo;ll be able to remember what job ID was associated with each job. We can use the following command instead.\nsbatch -p pool1 -n 1 -o ~/silly_sort.out -e ~/silly_sort.err example_script.sh We have added paths that Slurm should write the stdout (-o ~/silly_sort.out) and stderr (-e ~/silly_sort.err) for the job.\nWhat if we think this is too slow and we want to parallelize it. We can use the --parallel option for sort.\n# contents of example_script.sh #!/bin/bash  seq 1 10000 | shuf | sort -n --parallel=8 Now we can\u0026rsquo;t just ask for a single task. Each task by default is given a single CPU, but we want 8 CPUs for our one task. We can use the following instead.\nsbatch -p pool1 -n 1 -c 8 -o ~/silly_sort.out -e ~/silly_sort.err example_script.sh This requests 8 CPUs for each task (-c 8) in our job.\nNow let\u0026rsquo;s say we actually want to do our original silly sort multiple times for different sequences. Our example_script.sh might now look like this.\n# contents of example_script.sh #!/bin/bash  seq 1 10000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted1.txt seq 1 5 100000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted2.txt seq 1 20 1000000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted3.txt As it stands this script has a problem. It will wait for the first silly sort to finish, and then run the second and wait for it to finish, and then run the third. We can do this in parallel by modifying the script as follows.\n# contents of example_script.sh #!/bin/bash  srun --exclusive -n 1 -c 8 seq 1 10000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted1.txt \u0026amp; srun --exclusive -n 1 -c 8 seq 1 5 100000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted2.txt \u0026amp; srun --exclusive -n 1 -c 8 seq 1 20 1000000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted3.txt \u0026amp; wait Now each of our commands is run under srun. This makes sure that our allocated resources are split among the tasks in our job. The -n and -c flags are the same as in sbatch. The new option --exclusive makes sure that we don\u0026rsquo;t share resources across concurrent srun calls. The \u0026amp; at the ends makes the normally blocking srun command run in the background and wait waits for all background processes to finish. We can submit this new job with the following.\nsbatch -p pool1 -n 3 -c 8 -o ~/silly_sort.out -e ~/silly_sort.err example_script.sh Note that now we request 3 tasks with -n. In general we only need to request as many tasks per job that we plan to run in parallel. If we didn\u0026rsquo;t want to run our three silly sorts in parallel and instead wanted to run them serially we could remove the \u0026amp; and wait from our script and submit with\nsbatch -p pool1 -n 1 -c 8 -o ~/silly_sort.out -e ~/silly_sort.err example_script.sh We have one more problem. What if our sort implementation is strange in that it always uses slightly less than a gigabyte of memory for each --parallel. We can use the --mem-per-cpu argument to guarantee that we have enough memory. The script will now be\n# contents of example_script.sh #!/bin/bash  srun --exclusive -n 1 -c 8 --mem-per-cpu 1G seq 1 10000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted1.txt \u0026amp; srun --exclusive -n 1 -c 8 --mem-per-cpu 1G seq 1 5 100000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted2.txt \u0026amp; srun --exclusive -n 1 -c 8 --mem-per-cpu 1G seq 1 20 1000000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted3.txt \u0026amp; wait and it can be submitted with\nsbatch -p pool1 -n 3 -c 8 --mem-per-cpu 1G -o ~/silly_sort.out -e ~/silly_sort.err example_script.sh This command is starting to get ugly. If we don\u0026rsquo;t care about executing our script except on our cluster there is a way to make this cleaner.\n# contents of example_script.sh #!/bin/bash  #SBATCH -p pool1 #SBATCH -n 3 #SBATCH -c 8 #SBATCH --mem-per-cpu 1G #SBATCH -o ~/silly_sort.out #SBATCH -e ~/silly_sort.err  srun --exclusive -n 1 -c 8 --mem-per-cpu 1G seq 1 10000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted1.txt \u0026amp; srun --exclusive -n 1 -c 8 --mem-per-cpu 1G seq 1 5 100000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted2.txt \u0026amp; srun --exclusive -n 1 -c 8 --mem-per-cpu 1G seq 1 20 1000000 | shuf | sort -n --parallel=8 \u0026gt; ~/silly_sorted3.txt \u0026amp; wait Now we can simply submit with sbatch example_script.sh. Lines that begin with #SBATCH will have their flags read from the script and passed automatically to the sbatch command.\n"},{"id":1,"href":"/lane_custer/slurm-basics/connecting/","title":"Connecting to Lane","parent":"Slurm Basics","content":"The Lane cluster has the host name lanec1.compbio.cs.cmu.edu. You can connect to Lane via ssh with the command\nssh USERNAME@lanec1.compbio.cs.cmu.edu for Linux and OSX systems. If you are using Windows you can either use PuTTY or WSL. All following instructions operate under the assumption you use WSL if you\u0026rsquo;re a Windows user.\nFor a more compact representation you can create directory ~/.ssh if it doesn\u0026rsquo;t exist and store login information for Lane as follows.\nmkdir -p ~/.ssh cd ~/.ssh cat \u0026lt;\u0026lt; EOL \u0026gt;\u0026gt; config Host lane User USERNAME HostName lanec1.compbio.cs.cmu.edu EOL The above configuration creates a local configuration entry for a remote host lanec1.compbio.cs.cmu.edu for a user with remote username USERNAME. This whole configuration is stored under the name lane. Now, to ssh into lane all you need to run is ssh lane. This ssh configuration file also works with scp and rsync. You can also add your password here. I strongly recommend you don\u0026rsquo;t.\nExternal Resources      ssh config information scp man page rsync man page  "},{"id":2,"href":"/lane_custer/dependency-management/conda/creating-envs/","title":"Creating Conda Environments","parent":"Conda","content":"You can create conda environments with the conda create command. For more information about the last example see Transferring Conda Environments.\n# create an environment named py27 that contains python 2.7 conda create -n py27 python=2.7  # create an environment named rdkit that contains a python 3 version and compatible rdkit installation conda create -n rdkit -c conda-forge python=3 rdkit  # copy the rdkit environment to another environment named new_rdkit conda create -n new_rdkit --clone rdkit  # create environment from environment.yaml conda create --file environment.yaml    Useful Options Description     -n Name of conda environment to create   -c conda channel to use. Common useful ones are conda-forge for generic things not in the base conda repository and bioconda for comp bio software   --file Path to environment.yaml file described in Transferring Conda Environments   --clone Name of conda environment to copy for this new environment    External Resources      conda-forge bioconda anaconda package repository  "},{"id":3,"href":"/lane_custer/dependency-management/","title":"Dependency Management","parent":"Lane Cluster Documentation","content":"Conda contains information about installing conda, creating conda environments, activating conda environments, and transferring conda environments across machines.\nModules contains information about using and creating modules to share software with other users.\n"},{"id":4,"href":"/lane_custer/dependency-management/modules/modulefile-dirs/","title":"Modulefile Directories","parent":"Modules","content":"The way available modules are determined is by modulefiles in directories. You can add your own modulefile directory with module use PATH/TO/DIR. Let\u0026rsquo;s use my own modulefile directory and see what we have.\nmodule use /projects/mohimanilab/mustafa/tools/modulefiles module avail # output (only new section) # # ----------------------------------------------- /projects/mohimanilab/mustafa/tools/modulefiles ----------------------------------------------- # cudatoolkit/10.0 cudnn/6.0 fingerprinter tfcuda/1.10 tfcuda/1.15 tfcuda/1.6 tfcuda/2.1 # cudatoolkit/10.1 cudnn/7.4 proteowizard tfcuda/1.11 tfcuda/1.2 tfcuda/1.7 tfcuda/2.2 # cudatoolkit/8.0 cudnn/7.6 rust tfcuda/1.12 tfcuda/1.3 tfcuda/1.8 tfcuda/2.3 # cudatoolkit/9.2 db-search-tools tfcuda/1.0 tfcuda/1.13 tfcuda/1.4 tfcuda/1.9 # cudnn/5.1 dereplicator tfcuda/1.1 tfcuda/1.14 tfcuda/1.5 tfcuda/2.0 ls -l /projects/mohimanilab/mustafa/tools/modulefiles # output: # # total 87 # drwxrwsr-x 3 mguler mohimanilab 6 Nov 4 22:59 cudatoolkit # -rw-rw-r-- 1 mguler mohimanilab 611 Nov 4 23:07 cudatoolkit_common # drwxrwsr-x 2 mguler mohimanilab 6 Nov 4 19:28 cudnn # -rw-rw-r-- 1 mguler mohimanilab 625 Nov 4 23:09 cudnn_common # -rw-rw-r-- 1 mguler mohimanilab 1667 Nov 2 11:29 db-search-tools # -rw-rw-r-- 1 mguler mohimanilab 580 Apr 5 2020 dereplicator # -rw-rw-r-- 1 mguler mohimanilab 368 Jun 7 15:44 fingerprinter # -rw-rw-r-- 1 mguler mohimanilab 264 Apr 16 2020 proteowizard # -rw-rw-r-- 1 mguler mohimanilab 276 Apr 4 2020 rust # drwxrwsr-x 2 mguler mohimanilab 22 Nov 4 23:15 tfcuda Notice that we don\u0026rsquo;t see all the files in this directory when we look at module avail. This is because only files that contain the magic cookie will be loaded as modules. Let\u0026rsquo;s look at a few files.\nhead -n 1 /projects/mohimanilab/mustafa/tools/modulefiles/rust # output: # # #%Module head -n 1 /projects/mohimanilab/mustafa/tools/modulefiles/cudatoolkit/10.0 # output: # # #%Module head -n 1 # output: # # # Common modulefile for cuDNN Only the files that begin with #%Module are counted as modulefiles for module avail.\n"},{"id":5,"href":"/lane_custer/dependency-management/modules/","title":"Modules","parent":"Dependency Management","content":"Modules are method for modified a user\u0026rsquo;s environment in a reversible way. They can dynamically modify a user\u0026rsquo;s environment.\n"},{"id":6,"href":"/lane_custer/slurm-basics/transferring-data/rsync/","title":"rsync","parent":"Transferring Data","content":"This is another cp-like command with support for file transfer over networks. However, as the name suggests, this is a sync operation. This means that if some files exist unmodified in both the source and destination they will not be copied, saving some time. Additionally, rsync is considerably more flexible than scp with the trade-off of being a bit more complicated to use. Just like scp, rsync respects ssh configurations. The man page for rsync includes many examples that are useful.\nExternal Resources      rsync Man Page Nice Summary of Differences between rsync and scp  "},{"id":7,"href":"/lane_custer/slurm-basics/interactive-sessions/","title":"Interactive Sessions","parent":"Slurm Basics","content":"The way clusters are generally designed is there is a single, relatively small computer used as a \u0026ldquo;head\u0026rdquo; node. Users when executing ssh are actually connecting to this head node. Since this node handles all the initial user connection traffic nothing computationally intensive should be run by users on the head node. Processes that use large amounts of memory, CPU, or execute a lot of IO commands on the head node slow logins for other users severely.\nThe easiest way to avoid accidentally doing this is to immediately request an interactive session after connecting to a cluster. On Lane you can run the following.\nsrun -n 1 -p interactive --pty bash If it worked you will now see @compute-... in your shell prompt. You can now run anything you like, it will not affect other users. To release your interactive session and return to the head node run exit or type ctrl-d.\n"},{"id":8,"href":"/lane_custer/dependency-management/modules/modulefile-fmt/","title":"Modulefile Format","parent":"Modules","content":"We showed previously modulefiles must begin with the magic cookie #%Module, but what do modulefiles consist of? Modulefiles are Tcl scripts that modify a user\u0026rsquo;s environment. Let\u0026rsquo;s look at my rust module as an example.\n# contents of /projects/mohimanilab/mustafa/tools/modulefiles/rust #%Module ## ## Rust modulefile ## ## modulefiles/ ##  set ver 1.39.0 set msg \u0026#34;This module adds necessary paths and variables to use rust\u0026#34;  proc ModulesHelp { } {  puts stderr $msg }  module-whatis \u0026#34;Use rust $ver\u0026#34;  prepend-path PATH /projects/mohimanilab/mustafa/cargo/bin This is a very simple modulefile. It sets the variable ver to 1.39.0, adds a whatis definition and then simply prepends the path to my rust installation to PATH. You can get a summary of what a module does with the module show command.\nmodule show rust # output: # # ------------------------------------------------------------------ # /projects/mohimanilab/mustafa/tools/modulefiles/rust: #  # module-whatis Use rust 1.39.0 # prepend-path PATH /projects/mohimanilab/mustafa/cargo/bin # ------------------------------------------------------------------- module show db-search-tools # output: # # ------------------------------------------------------------------- # /projects/mohimanilab/mustafa/tools/modulefiles/db-search-tools: #  # module load rust # module-whatis Use MAGMa+, CFM-ID, and CSI:FingerID # prepend-path PATH /projects/mohimanilab/mustafa/tools/time-1.9/bin # setenv MAGMAPLUS_CLASSIFIER_PATH /projects/mohimanilab/mustafa/tools/magma+/MAGMa-plus # setenv MAGMA_ROOT /projects/mohimanilab/mustafa/tools/magma+/MAGMa-plus # setenv JAVA_HOME /projects/mohimanilab/mustafa/tools/java/jdk-11.0.7+10-jre/ # prepend-path PATH /projects/mohimanilab/mustafa/tools/magma+/bin # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/boost/boost_1_59_0 # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/rdkit/RDKit_2013_09_1/lib # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/lp_solve/lp_solve_5.5/lpsolve55/bin/ux64 # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/liblbfgs/lib # prepend-path PATH /projects/mohimanilab/mustafa/tools/cfm-id/cfm/bin # prepend-path PATH /projects/mohimanilab/mustafa/tools/java/jdk-11.0.7+10-jre/bin # prepend-path PATH /projects/mohimanilab/mustafa/tools/csi-fingerid/sirius-linux64-headless-4.4.29/bin # prepend-path PATH /projects/mohimanilab/mustafa/dereplicator/cycloquest_minimal # setenv DEREP_BASE /projects/mohimanilab/mustafa/dereplicator/cycloquest_minimal # prepend-path PATH /projects/mohimanilab/mustafa/tools/search_runner/target/release # ------------------------------------------------------------------- The most commonly used commands are setenv which sets an environment variable that is active when the module is loaded and prepend-path which adds a directory to a PATH-like variable when the module is loaded.\n"},{"id":9,"href":"/lane_custer/slurm-basics/submitting-jobs/useful-flags/","title":"Useful sbatch Flags","parent":"Submitting Jobs","content":"In the following table X is an integer and S is a string.\n   Flag Value Format Description     -p S Partition that job should be submitted to. Can be a comma-separated list if you aren\u0026rsquo;t concerned with forcing a particular partition   -n X Number of concurrent tasks you will run for this job. Tasks can be allocated from within your job script with srun   -c X Number of CPUs each task will use for this job   --mem-per-cpu X[KMGT] for KB,MB,GB,TB respectively Amount of memory per CPU this job requires   --mem X[KMGT] for KB,MB,GB,TB respectively Amount of memory this job requires total, not per CPU   -t X-XX:XX:XX Sets a maximum running time for your job. Provided value format is in days-hours:minutes:seconds. For more formatting see --time entry in sbatch man page   -J S Name of your job   -o S, filepath Path where the stdout of this job should be written   -e S, filepath Path where the stderr of this job should be written    For srun these are the same. The additional flag for srun that isn\u0026rsquo;t for sbatch that should be kept in mind is --exclusive.\nExternal Resources      sbatch man Page srun man Page  "},{"id":10,"href":"/lane_custer/dependency-management/conda/using-envs/","title":"Using Conda Environments","parent":"Conda","content":"After you have created an environment you need to activate it before you can access its contents. If you are running an interactive job you can do this via conda activate ENV_NAME. However, this does not always work as expected when it is part of a job submitting with sbatch (See Submitting Jobs for more information on job submission). You can work around this by activating a conda environment with the command\nsource activate ENV_NAME Once you have activated a conda environment via either method you have access to everything you installed in there. You can install more packages with the conda install command. Specific versions of package names can be specific with an = after the package name. It\u0026rsquo;s recommended that if you know all the packages you want beforehand you group the installations into one install command. This is because conda contains a SAT solver to pick package versions and if all the packages are given at once it can decide quicker.\nYou can also install packages from pip in a conda environment. Make sure you activate your conda environment first, then use pip as you normally would. Generally pip dependencies are not checked for version compatibility, so if possible use the conda package for the library you\u0026rsquo;re interested in.\n"},{"id":11,"href":"/lane_custer/slurm-basics/submitting-jobs/array-jobs/","title":"Array Jobs","parent":"Submitting Jobs","content":"What if I want to perform the same computation on a very large number of inputs? The Slurm solution to this is an array job. An array job executes the same script many times. It is specified with the sbatch flag -a. For each integer value of -a Slurm will create a distinct job and within that job set the environment variable SLURM_ARRAY_TASK_ID to the associated value of -a.\n   Example -a Explanation     -a 1-100 Run an array job with array values 1,2,3,\u0026hellip;,100   -a 100-200 Run an array job with array values 100,102,103,\u0026hellip;,200   -a 0-15:4 Run an array job with array values 0,4,8,12   -a 0-15:2 Run an array job with array values 0,2,4,6,8,10,12,14   -a 0-15%2 Run an array job with array values 0,1,2,3,\u0026hellip;,15 but only ever have 2 running simultaneously    There are limitations to array jobs. The array indices cannot exceed the maximum array size configured on the Slurm cluster. You can check this value with\nscontrol show config | grep MaxArraySize # output: # # MaxArraySize = 1001 Note the name of this configuration value is misleading. It would make you think -a 1000-2000 would be acceptable since the array length is less than 1001. However, the way this configuration value is applied it actually restricts the maximum value of an index, not the array size. A MaxArraySize of 1001 means your -a value cannot have an index that exceeds 1001.\nA Common Array Paradigm     Say we have a data file for which we want to compute something from each line. For example, we could have data.smi that contains a SMILES string on each line and we want to run expensive_script that accepts a SMILES string as a parameter and writes some computed value to stdout. Let\u0026rsquo;s make a job script.\n# contents of array_example.sh #!/bin/bash  #SBATCH -p pool1 #SBATCH -n 1 #SBATCH --mem 5G #SBATCH -o ~/array_example_%a.out #SBATCH -e ~/array_example_%a.err  # extract the smiles associated with the line in data.smi for our array task ID smiles=\u0026#34;$(sed -n \u0026#34;${SLURM_ARRAY_TASK_ID}p\u0026#34; data.smi)\u0026#34;  # run the script on that smiles srun -n 1 --mem 5G expensive_script $smiles There are a few new things here.\nFirst, we have %a in the stdout and stderr files. The value %a gets expanded by Slurm into the same value as $SLURM_ARRAY_TASK_ID. These % formatting strings allow you to use Slurm variables in your Slurm parameters. For more information see the filename pattern section of the sbatch man page. Using %a we guarantee that each array task in array job has its logs written to separate files.\nNext, we have this line:\nsmiles=\u0026#34;$(sed -n \u0026#34;${SLURM_ARRAY_TASK_ID}p\u0026#34; data.smi)\u0026#34; The command sed -n \u0026quot;NUMBERp\u0026quot; FILE prints a particular line number in a file. In our case it pulls out the SMILES on the line of data.smi that is the same as our array task ID. The $() captures this output and stores in the variable smiles.\nWe can submit our example script with sbatch -a 1-100 array_example.sh to process the first 100 lines of data.smi. We can also use sbatch -a 1-1000 array_example.sh to process the first 1000 lines. Remember, our MaxArraySize configuration is 1001, so we can\u0026rsquo;t actually have values of -a larger than this. So what do we do if data.smi has more than 1000 lines?\nLet\u0026rsquo;s look at this modified script.\n# contents of big_array_example.sh #!/bin/bash  #SBATCH -p pool1 #SBATCH -n 1 #SBATCH --mem 5G #SBATCH -o ~/array_example_%x_%a.out #SBATCH -e ~/array_example_%x_%a.err  # determine the line number from the job name and task ID line_num=$((SLURM_ARRAY_TASK_ID + $(echo $SLURM_JOB_NAME | cut -f2 -d_)))  # extract the smiles associated with the line in data.smi for our array task ID smiles=\u0026#34;$(sed -n \u0026#34;${line_num}p\u0026#34; data.smi)\u0026#34;  # run the script on that smiles srun -n 1 --mem 5G expensive_script $smiles The changes are now our logs contain the %x formatter, which expands to the job name specified via sbatch flag -J. This job name is stored in the environment variable SLURM_JOB_NAME as well. In this line\nline_num=$((SLURM_ARRAY_TASK_ID + $(echo $SLURM_JOB_NAME | cut -f2 -d_))) We add the array task ID to a number in the job name. This is helpful because now we can do the following.\nsbatch -J smilesprocessing_0 -a 1-1000 big_array_example.sh sbatch -J smilesprocessing_1000 -a 1-1000 big_array_example.sh sbatch -J smilesprocessing_2000 -a 1-1000 big_array_example.sh We no longer violate MaxArraySize but we can process lines past line 1000 in data.smi by adding the array task ID to the part of the job name that is after the _. The output for line 1015 in data.smi will be stored in ~/array_example_smilesprocesing_1000_15.out.\nWe can run into a few new issues though.\nFirst, there is maximum number of jobs each user can submit.\nscontrol show config | grep MaxJobCount # output: # # MaxJobCount = 10000 You cannot submit more than 10000 jobs at once on Lane. Be careful of this.\nSecond, doing this will quickly flood queues and take control of all resources. I\u0026rsquo;ve made this mistake, and it can be inconsiderate to every else. There is a simple way around this.\nsbatch -J smilesprocessing_0 -a 1-1000%50 big_array_example.sh # previous submission had job ID 123 sbatch -J smilesprocessing_1000 -a 1-1000%50 -d afterany:123 big_array_example.sh # previous submission had job ID 124 sbatch -J smilesprocessing_2000 -a 1-1000%50 -d afterany:124 big_array_example.sh The %50 means that only 50 of the array job\u0026rsquo;s array tasks will run at the same time ever. The -d flag specifies a job dependency. For more information see Job Dependencies. In this case the first 1000 lines will be processed 50 at a time. Then, regardless of errors in the first 1000 lines the lines 1000-2000 will be processed 50 at a time. However, this will only happen once the first array job has finished. Using design pattern means you\u0026rsquo;ll only use a fixed amount of the cluster\u0026rsquo;s resources at a given time but also lets you set and forget these large array jobs.\n"},{"id":12,"href":"/lane_custer/dependency-management/conda/transferring-envs/","title":"Transferring Conda Environments","parent":"Conda","content":"Once you have set up an environment the way you like it you may want to use the same environment on a different machine. If the other machine is running the same overarching OS as yours (running Linux locally and remotely is the most common case of this) you can simply run\nconda activate ENV_NAME conda env export | grep -v \u0026#34;^prefix\u0026#34; \u0026gt; environment.yaml This will create an environment.yaml file that contains all the packages you install in this conda environment along with their frozen versions. You can then copy this file to your other system and run\nconda create --file environment.yaml to create a copy of this environment.\nIf the other machine runs a different operating system you can still usually transfer environments. However, now you should use\nconda activate ENV_NAME conda env export --from-history | grep -v \u0026#34;^prefix\u0026#34; \u0026gt; environment.yaml This will essentially serialize the exact install commands you called in this environment. A new environment can be created in the same way as before, but now conda will replay the install commands instead of pulling down exact versions.\nExternal Resources      conda env export Man Page  "},{"id":13,"href":"/lane_custer/slurm-basics/transferring-data/","title":"Transferring Data","parent":"Slurm Basics","content":"You will likely bump into multiple occasions where you either need to download files from the cluster to your local machine, or upload files from your local machine to the cluster. If possible, for larger datasets download these directly to the cluster in an interactive partition.\n"},{"id":14,"href":"/lane_custer/dependency-management/modules/using-modules/","title":"Using Modules","parent":"Modules","content":"Once you have added a modulefile directory with module use you can load modules with module load and unload them with module unload. At any point you can use module list to see what modules you have active. Additionally, you can use module purge to unload all loaded modules. You can add module load commands to the beginning of jobs scripts to use modules in your jobs. For more information on submitting jobs see Submitting Jobs.\n"},{"id":15,"href":"/lane_custer/slurm-basics/examining-partitions/","title":"Examining Partitions","parent":"Slurm Basics","content":"When logging into a new Slurm cluster you can examine characteristics of available partitions with the sinfo command. Below are some useful examples for Lane. Your available partition lists may look different.\n# List names of partitions you have access to sinfo -o \u0026#34;%20P\u0026#34; # output: # # PARTITION # DEBUG # short1 # interactive # moh1 # moh2-gpu # pool1 # pool3-bigmem  # List total resources for each partition # CPUS and MEMORY are given per node # NODES are given in the format Allocated/Idle sinfo -o \u0026#34;%20P %10A %10c %10m %25f %20G %20N\u0026#34; # output: # # PARTITION NODES(A/I) CPUS MEMORY AVAIL_FEATURES GRES NODELIST # DEBUG 0/0 0 0 (null) (null) # short1 0/3 8 32000+ rack-0,8CPUs (null) compute-0-[9-11] # short1 1/2 32 64153 rack-3,32CPUs (null) compute-3-[32-34] # interactive 0/3 8 32000+ rack-0,8CPUs (null) compute-0-[9-11] # moh1 2/3 48 257364 rack-0,48CPUs (null) compute-0-[7,20-21,2 # moh1 0/2 56 128530 rack-1,56CPUs (null) compute-1-[2-6] # moh2-gpu 0/1 32 257348 rack-4,32CPUs, gpu:4 compute-4-18 # pool1 0/4 16 48059 rack-0,16CPUs (null) compute-0-[4-6,8] # pool1 0/8 8 23936 rack-0,8CPUs (null) compute-0-[22-28,30] # pool1 0/11 8 23933+ rack-1,8CPUs (null) compute-1-[7-10,20-2 # pool1 0/5 16 48059 rack-1,16CPUs (null) compute-1-[14-18] # pool3-bigmem 0/1 32 257757 rack-0,32CPUs (null) compute-0-12 # pool3-bigmem 0/1 8 128761 rack-1,8CPUs (null) compute-1-35  # List free resources  # CPUS in the format Allocated/Idle/Other/Total sinfo -o \u0026#34;%20P %20e %20m %20C %f\u0026#34; # output: # # PARTITION FREE_MEM MEMORY CPUS(A/I/O/T) AVAIL_FEATURES # DEBUG 0 0 0/0/0/0 (null) # short1 29863-45543 32000+ 0/24/0/24 rack-0,8CPUs # short1 39072-61998 64153 16/80/0/96 rack-3,32CPUs # interactive 29863-45543 32000+ 0/24/0/24 rack-0,8CPUs # moh1 29816-250476 257364 148/92/240/480 rack-0,48CPUs # moh1 34069-94091 128530 0/168/112/280 rack-1,56CPUs # moh2-gpu 167177 257348 1/31/0/32 rack-4,32CPUs, # pool1 13063-N/A 23933+ 2/86/8/96 rack-1,8CPUs # pool1 40995-45646 48059 0/64/0/64 rack-0,16CPUs # pool1 21716-23147 23936 0/64/0/64 rack-0,8CPUs # pool1 30473-45375 48059 3/77/0/80 rack-1,16CPUs # pool3-bigmem 37394 128761 1/7/0/8 rack-1,8CPUs # pool3-bigmem 254574 257757 0/32/0/32 rack-0,32CPUs Shared Partitions on Lane        Partition Name Description     short1 I\u0026rsquo;ve never used this. It seems to be intended for short jobs   interactive Intended for interactive sessions. See Interactive Sessions   pool1 This is the shared partition across all of CBD.   pool3-bigmem This is a large memory partition shared across all of CBD    Your may have access to more partitions specific to your group. If so, please ask your advisor or a senior student the purpose of those partitions.\nExternal Resources      sinfo Man Page  "},{"id":16,"href":"/lane_custer/slurm-basics/submitting-jobs/job-dependencies/","title":"Job Dependencies","parent":"Submitting Jobs","content":"You may end up wanting to have jobs wait for other jobs before they execute, either to guarantee some preprocessing or conserve cluster resources. This can be accomplished with the -d flag of sbatch. The -d flag takes values of the format type:job_id.\n   -d Type Explanation     after After job ID has begun, not ended   afterany After job ID has finished, regardless of error status   afterok After job ID has finished and has not exited with an error   afternotok After job ID has finished and has exited with an error   aftercorr After array task of job ID corresponding with this array job\u0026rsquo;s array task has finished successfully. For example array task 1 of your new job will only run after array task 1 of your dependency job has finished without an error    "},{"id":17,"href":"/lane_custer/dependency-management/modules/summary/","title":"Module Command Summary","parent":"Modules","content":"   Command Description     module load MODULE Activates a module MODULE, running its modulefile   module unload MODULE Removes an active module MODULE, undoing everything done in its modulefile   module add MODULE Same as module load MODULE   module rm MODULE Same as module unload MODULE   module show MODULE Show what module MODULE will do when loaded   module list Show all loaded modules   module avail Show all available modules   module purge Unload all loaded modules   module use DIR Use DIR as a modulefile directory    "},{"id":18,"href":"/lane_custer/slurm-basics/storage/","title":"Storage on Lane","parent":"Slurm Basics","content":"There are a few storage systems on Lane. First is your home directory (~, /home/$(whoami)). Home directories have 500GB are by default are only accessible by you. You can examine characteristics of your home directory with the command\ndf -ah | grep -P \u0026#34;(Filesystem|$(whoami))\u0026#34; # output: # # Filesystem Size Used Avail Use% Mounted on # nas-3-31:/volume01/home/mguler 500G 54G 447G 11% /home/mguler In addition to your home directory you will likely have access to network attached storage (NAS) filesystems specific to your lab. Please consult with your advisor or senior students for questions about those filesystems.\nExternal Resources      df Man Page  "},{"id":19,"href":"/lane_custer/slurm-basics/submitting-jobs/","title":"Submitting Jobs","parent":"Slurm Basics","content":"Now that we understand what partitions we have we can talk about submitting jobs. Jobs are typically submitted with the sbatch command and each job will contain some amount of tasks started with srun.\n"},{"id":20,"href":"/lane_custer/slurm-basics/monitoring-jobs/","title":"Monitoring Jobs","parent":"Slurm Basics","content":"After you have submitted your jobs you likely want to monitor their status. This is done with the squeue command. Executed without any flags it will list all queued jobs across the whole cluster. Generally, you only will want to look at your jobs. You can do this with squeue -u $(whoami). Let\u0026rsquo;s look at my jobs.\nsqueue -u mguler # output: # # JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) # 349613_1 moh1,pool train_gn mguler PD 0:00 1 (DependencyNeverSatisfied) # 349613_2 moh1,pool train_gn mguler PD 0:00 1 (DependencyNeverSatisfied) # 349613_3 moh1,pool train_gn mguler PD 0:00 1 (DependencyNeverSatisfied) # 349613_4 moh1,pool train_gn mguler PD 0:00 1 (DependencyNeverSatisfied) # 349613_5 moh1,pool train_gn mguler PD 0:00 1 (DependencyNeverSatisfied) # 349388 moh2-gpu train_zi mguler R 15:24:51 1 compute-4-18 We can see I have 6 jobs. The first five are part of an array job, as we can see by the _ in the JOBID. They were submitted to both moh1 and pool1 as shown by PARTITION and requested 1 node as shown by NODES. They are all in the PD or pending state because their dependency was never satisfied (columns ST and NODELIST(REASON)). This happens when you use the afterok dependency and your dependency exits with an error. The 6th job is currently in the R or running state and is running on node compute-4-18 on moh2-gpu. We can see it has been running for 15 hours, 24 minutes, and 51 seconds in the TIME column. The most common job states you\u0026rsquo;ll see are PD for pending, R for running, and CG for completing.\nExternal Resources      squeue man page  "},{"id":21,"href":"/lane_custer/slurm-basics/stopping-jobs/","title":"Stopping Jobs","parent":"Slurm Basics","content":"If you want to stop your job first find your job ID with squeue then run scancel JOBID. For array jobs using just the job ID before the underscore you will cancel all array tasks in the array job. Using the underscore you will only cancel a single array step.\nExternal Resources      scancel man page  "},{"id":22,"href":"/lane_custer/dependency-management/","title":"Dependency Management","parent":"Lane Cluster Documentation","content":"Reading This Document     Conda contains information about installing conda, creating conda environments, activating conda environments, and transferring conda environments across machines.\nConda     conda is a python-oriented environment manager. While it is primarily geared towards python it can be used for many things. conda packages are pre-compiled for a particular system, so you will not need to deal with compiling your own dependencies. conda environments sandbox dependencies from each other so different environments can exist and be used without polluting the global package space.\nExternal Resources:\n conda User Guide  Installing Conda     You may already have conda installed under a shared FS for your lab. Check if this is the case before proceeding. If you use this installation please make sure you do not modify existing environments, as it could break other users\u0026rsquo; workflows.\nTo install your own copy go to the Miniconda installation page and copy the link to the latest linux installer. As of writing this it is for Python 3.8. Then run\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh and follow the prompts. Be sure that conda init was run. You can do whatever you like to your own conda installation\u0026rsquo;s environments.\nExternal Resources:\n Miniconda Installation Page  Creating Conda Environments     You can create conda environments with the conda create command. For more information about the last example see Transferring Conda Environments.\n# create an environment named py27 that contains python 2.7 conda create -n py27 python=2.7  # create an environment named rdkit that contains a python 3 version and compatible rdkit installation conda create -n rdkit -c conda-forge python=3 rdkit  # copy the rdkit environment to another environment named new_rdkit conda create -n new_rdkit --clone rdkit  # create environment from environment.yaml conda create --file environment.yaml    Useful Options Description     -n Name of conda environment to create   -c conda channel to use. Common useful ones are conda-forge for generic things not in the base conda repository and bioconda for comp bio software   --file Path to environment.yaml file described in Transferring Conda Environments   --clone Name of conda environment to copy for this new environment    External Resources:\n conda-forge bioconda anaconda package repository  Using Conda Environments     After you have created an environment you need to activate it before you can access its contents. If you are running an interactive job you can do this via conda activate ENV_NAME. However, this does not always work as expected when it is part of a job submitting with sbatch (See Submitting Jobs for more information on job submission). You can work around this by activating a conda environment with the command\nsource activate ENV_NAME Once you have activated a conda environment via either method you have access to everything you installed in there. You can install more packages with the conda install command. Specific versions of package names can be specific with an = after the package name. It\u0026rsquo;s recommended that if you know all the packages you want beforehand you group the installations into one install command. This is because conda contains a SAT solver to pick package versions and if all the packages are given at once it can decide quicker.\nYou can also install packages from pip in a conda environment. Make sure you activate your conda environment first, then use pip as you normally would. Generally pip dependencies are not checked for version compatibility, so if possible use the conda package for the library you\u0026rsquo;re interested in.\nTransferring Conda Environments     Once you have set up an environment the way you like it you may want to use the same environment on a different machine. If the other machine is running the same overarching OS as yours (running Linux locally and remotely is the most common case of this) you can simply run\nconda activate ENV_NAME conda env export | grep -v \u0026#34;^prefix\u0026#34; \u0026gt; environment.yaml This will create an environment.yaml file that contains all the packages you install in this conda environment along with their frozen versions. You can then copy this file to your other system and run\nconda create --file environment.yaml to create a copy of this environment.\nIf the other machine runs a different operating system you can still usually transfer environments. However, now you should use\nconda activate ENV_NAME conda env export --from-history | grep -v \u0026#34;^prefix\u0026#34; \u0026gt; environment.yaml This will essentially serialize the exact install commands you called in this environment. A new environment can be created in the same way as before, but now conda will replay the install commands instead of pulling down exact versions.\nExternal Resources:\n conda env export Man Page  Modules     Modules are method for modified a user\u0026rsquo;s environment in a reversible way. They can dynamically modify a user\u0026rsquo;s environment.\nLane\u0026rsquo;s Default Modules     Without any other modification you can run module avail to see what default modules are available on Lane.\nmodule avail # output: # # ------------------------------------------------------- /usr/share/Modules/modulefiles -------------------------------------------------------- # cuda-10.0 matlab-9.5 R-3.5.3 singularity/ImageMagick-v6.9.10-23 # cuda-8.0 matlab-9.7 rocks-openmpi singularity/KNIME-v4.1.1 # cudnn-10.0-7.3 module-git rocks-openmpi_ib singularity/meme-suite-v5.1.0 # cudnn-8.0-7.1 module-info singularity/bedtools-v2.29.2 singularity/neofetch-v7.0.0 # dot modules singularity/bftools-v6.3.1 singularity/r-base-v3.6.2 # ffmpeg-4.2.2 null singularity/cellorganizer-v2.8.1 singularity/samtools-v1.10 # gurobi902 opt-perl singularity/cowsay-v3.03 singularity/texlive-v3.14 # java-1.8.0 python27 singularity/FastQC-v0.11.9 use.own # maple2019 python27-extras singularity/gcc-v8.3.0 # mathematica-12.0 python36 singularity/genometools-v1.5.10 # mathematica-8.0 python36-extras singularity/genometools-v1.6.0 # # -------------------------------------------------------------- /etc/modulefiles --------------------------------------------------------------- You can see this output is split into sections based on modulefile directories.\nModulefile Directories     The way available modules are determined is by modulefiles in directories. You can add your own modulefile directory with module use PATH/TO/DIR. Let\u0026rsquo;s use my own modulefile directory and see what we have.\nmodule use /projects/mohimanilab/mustafa/tools/modulefiles module avail # output (only new section) # # ----------------------------------------------- /projects/mohimanilab/mustafa/tools/modulefiles ----------------------------------------------- # cudatoolkit/10.0 cudnn/6.0 fingerprinter tfcuda/1.10 tfcuda/1.15 tfcuda/1.6 tfcuda/2.1 # cudatoolkit/10.1 cudnn/7.4 proteowizard tfcuda/1.11 tfcuda/1.2 tfcuda/1.7 tfcuda/2.2 # cudatoolkit/8.0 cudnn/7.6 rust tfcuda/1.12 tfcuda/1.3 tfcuda/1.8 tfcuda/2.3 # cudatoolkit/9.2 db-search-tools tfcuda/1.0 tfcuda/1.13 tfcuda/1.4 tfcuda/1.9 # cudnn/5.1 dereplicator tfcuda/1.1 tfcuda/1.14 tfcuda/1.5 tfcuda/2.0 ls -l /projects/mohimanilab/mustafa/tools/modulefiles # output: # # total 87 # drwxrwsr-x 3 mguler mohimanilab 6 Nov 4 22:59 cudatoolkit # -rw-rw-r-- 1 mguler mohimanilab 611 Nov 4 23:07 cudatoolkit_common # drwxrwsr-x 2 mguler mohimanilab 6 Nov 4 19:28 cudnn # -rw-rw-r-- 1 mguler mohimanilab 625 Nov 4 23:09 cudnn_common # -rw-rw-r-- 1 mguler mohimanilab 1667 Nov 2 11:29 db-search-tools # -rw-rw-r-- 1 mguler mohimanilab 580 Apr 5 2020 dereplicator # -rw-rw-r-- 1 mguler mohimanilab 368 Jun 7 15:44 fingerprinter # -rw-rw-r-- 1 mguler mohimanilab 264 Apr 16 2020 proteowizard # -rw-rw-r-- 1 mguler mohimanilab 276 Apr 4 2020 rust # drwxrwsr-x 2 mguler mohimanilab 22 Nov 4 23:15 tfcuda Notice that we don\u0026rsquo;t see all the files in this directory when we look at module avail. This is because only files that contain the magic cookie will be loaded as modules. Let\u0026rsquo;s look at a few files.\nhead -n 1 /projects/mohimanilab/mustafa/tools/modulefiles/rust # output: # # #%Module head -n 1 /projects/mohimanilab/mustafa/tools/modulefiles/cudatoolkit/10.0 # output: # # #%Module head -n 1 # output: # # # Common modulefile for cuDNN Only the files that begin with #%Module are counted as modulefiles for module avail.\nModulefile Format     We showed previously modulefiles must begin with the magic cookie #%Module, but what do modulefiles consist of? Modulefiles are Tcl scripts that modify a user\u0026rsquo;s environment. Let\u0026rsquo;s look at my rust module as an example.\n# contents of /projects/mohimanilab/mustafa/tools/modulefiles/rust #%Module ## ## Rust modulefile ## ## modulefiles/ ##  set ver 1.39.0 set msg \u0026#34;This module adds necessary paths and variables to use rust\u0026#34;  proc ModulesHelp { } {  puts stderr $msg }  module-whatis \u0026#34;Use rust $ver\u0026#34;  prepend-path PATH /projects/mohimanilab/mustafa/cargo/bin This is a very simple modulefile. It sets the variable ver to 1.39.0, adds a whatis definition and then simply prepends the path to my rust installation to PATH. You can get a summary of what a module does with the module show command.\nmodule show rust # output: # # ------------------------------------------------------------------ # /projects/mohimanilab/mustafa/tools/modulefiles/rust: #  # module-whatis Use rust 1.39.0 # prepend-path PATH /projects/mohimanilab/mustafa/cargo/bin # ------------------------------------------------------------------- module show db-search-tools # output: # # ------------------------------------------------------------------- # /projects/mohimanilab/mustafa/tools/modulefiles/db-search-tools: #  # module load rust # module-whatis Use MAGMa+, CFM-ID, and CSI:FingerID # prepend-path PATH /projects/mohimanilab/mustafa/tools/time-1.9/bin # setenv MAGMAPLUS_CLASSIFIER_PATH /projects/mohimanilab/mustafa/tools/magma+/MAGMa-plus # setenv MAGMA_ROOT /projects/mohimanilab/mustafa/tools/magma+/MAGMa-plus # setenv JAVA_HOME /projects/mohimanilab/mustafa/tools/java/jdk-11.0.7+10-jre/ # prepend-path PATH /projects/mohimanilab/mustafa/tools/magma+/bin # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/boost/boost_1_59_0 # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/rdkit/RDKit_2013_09_1/lib # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/lp_solve/lp_solve_5.5/lpsolve55/bin/ux64 # prepend-path LD_LIBRARY_PATH /projects/mohimanilab/mustafa/tools/cfm-id/liblbfgs/lib # prepend-path PATH /projects/mohimanilab/mustafa/tools/cfm-id/cfm/bin # prepend-path PATH /projects/mohimanilab/mustafa/tools/java/jdk-11.0.7+10-jre/bin # prepend-path PATH /projects/mohimanilab/mustafa/tools/csi-fingerid/sirius-linux64-headless-4.4.29/bin # prepend-path PATH /projects/mohimanilab/mustafa/dereplicator/cycloquest_minimal # setenv DEREP_BASE /projects/mohimanilab/mustafa/dereplicator/cycloquest_minimal # prepend-path PATH /projects/mohimanilab/mustafa/tools/search_runner/target/release # ------------------------------------------------------------------- The most commonly used commands are setenv which sets an environment variable that is active when the module is loaded and prepend-path which adds a directory to a PATH-like variable when the module is loaded.\nUsing Modules     Once you have added a modulefile directory with module use you can load modules with module load and unload them with module unload. At any point you can use module list to see what modules you have active. Additionally, you can use module purge to unload all loaded modules. You can add module load commands to the beginning of jobs scripts to use modules in your jobs. For more information on submitting jobs see Submitting Jobs.\nModule Command Summary        Command Description     module load MODULE Activates a module MODULE, running its modulefile   module unload MODULE Removes an active module MODULE, undoing everything done in its modulefile   module add MODULE Same as module load MODULE   module rm MODULE Same as module unload MODULE   module show MODULE Show what module MODULE will do when loaded   module list Show all loaded modules   module avail Show all available modules   module purge Unload all loaded modules   module use DIR Use DIR as a modulefile directory    "},{"id":23,"href":"/lane_custer/categories/","title":"Categories","parent":"Lane Cluster Documentation","content":""},{"id":24,"href":"/lane_custer/dependency-management/conda/","title":"Conda","parent":"Dependency Management","content":"conda is a python-oriented environment manager. While it is primarily geared towards python it can be used for many things. conda packages are pre-compiled for a particular system, so you will not need to deal with compiling your own dependencies. conda environments sandbox dependencies from each other so different environments can exist and be used without polluting the global package space.\nExternal Resources      conda User Guide  "},{"id":25,"href":"/lane_custer/slurm-basics/defining-terms/","title":"Defining Terms","parent":"Slurm Basics","content":"There are some terms I use throughout that should be explained first to remove ambiguity.\n   Term Definition     cluster A remote server that consists of a collection of computers   resources CPUs, memory, GPUs, etc. that can be consumed by a program   node A single computer in a cluster, contains resources   partition A collection of nodes in a cluster with shared characteristics   job Some executable submitted to the cluster to run on some partition with some resources. Usually submitted via sbatch   task An atomic logical unit of a job. A job can have more than one task that runs within its allocated resources. Usually started via srun    "},{"id":26,"href":"/lane_custer/dependency-management/conda/installing/","title":"Installing Conda","parent":"Conda","content":"You may already have conda installed under a shared FS for your lab. Check if this is the case before proceeding. If you use this installation please make sure you do not modify existing environments, as it could break other users\u0026rsquo; workflows.\nTo install your own copy go to the Miniconda installation page and copy the link to the latest linux installer. As of writing this it is for Python 3.8. Then run\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda3-latest-Linux-x86_64.sh and follow the prompts. Be sure that conda init was run. You can do whatever you like to your own conda installation\u0026rsquo;s environments.\nExternal Resources      Miniconda Installation Page  "},{"id":27,"href":"/lane_custer/","title":"Lane Cluster Documentation","parent":"","content":""},{"id":28,"href":"/lane_custer/dependency-management/modules/lane-defaults/","title":"Lane's Default Modules","parent":"Modules","content":"Without any other modification you can run module avail to see what default modules are available on Lane.\nmodule avail # output: # # ------------------------------------------------------- /usr/share/Modules/modulefiles -------------------------------------------------------- # cuda-10.0 matlab-9.5 R-3.5.3 singularity/ImageMagick-v6.9.10-23 # cuda-8.0 matlab-9.7 rocks-openmpi singularity/KNIME-v4.1.1 # cudnn-10.0-7.3 module-git rocks-openmpi_ib singularity/meme-suite-v5.1.0 # cudnn-8.0-7.1 module-info singularity/bedtools-v2.29.2 singularity/neofetch-v7.0.0 # dot modules singularity/bftools-v6.3.1 singularity/r-base-v3.6.2 # ffmpeg-4.2.2 null singularity/cellorganizer-v2.8.1 singularity/samtools-v1.10 # gurobi902 opt-perl singularity/cowsay-v3.03 singularity/texlive-v3.14 # java-1.8.0 python27 singularity/FastQC-v0.11.9 use.own # maple2019 python27-extras singularity/gcc-v8.3.0 # mathematica-12.0 python36 singularity/genometools-v1.5.10 # mathematica-8.0 python36-extras singularity/genometools-v1.6.0 # # -------------------------------------------------------------- /etc/modulefiles --------------------------------------------------------------- You can see this output is split into sections based on modulefile directories.\n"},{"id":29,"href":"/lane_custer/slurm-basics/monitoring-jobs/more-job-details/","title":"More Job Details","parent":"Monitoring Jobs","content":"We have some options to get more details about jobs. Looking at my train_zinc job we can break down status by task with\nsacct -j 349388 # output: # # JobID JobName Partition Account AllocCPUS State ExitCode # ------------ ---------- ---------- ---------- ---------- ---------- -------- # 349388 train_zin+ moh2-gpu local 1 RUNNING 0:0 # 349388.batch batch local 1 RUNNING 0:0 # 349388.exte+ extern local 1 RUNNING 0:0 # 349388.1 python local 1 RUNNING 0:0 and get all the job\u0026rsquo;s configuration with\nscontrol show job 349388 # output: # # JobId=349388 JobName=train_zinc.sh # UserId=mguler(20931) GroupId=mguler(20931) MCS_label=N/A # Priority=1207 Nice=0 Account=local QOS=normal WCKey=*default # JobState=RUNNING Reason=None Dependency=(null) # Requeue=1 Restarts=2 BatchFlag=2 Reboot=0 ExitCode=0:0 # RunTime=15:35:03 TimeLimit=1-00:00:00 TimeMin=N/A # SubmitTime=2020-11-04T20:36:07 EligibleTime=2020-11-04T20:38:08 # AccrueTime=2020-11-04T20:38:08 # StartTime=2020-11-04T20:38:36 EndTime=2020-11-05T20:38:36 Deadline=N/A # SuspendTime=None SecsPreSuspend=0 LastSchedEval=2020-11-04T20:38:36 # Partition=moh2-gpu AllocNode:Sid=lanec1.compbio.cs.cmu.edu:18843 # ReqNodeList=(null) ExcNodeList=(null) # NodeList=compute-4-18 # BatchHost=compute-4-18 # NumNodes=1 NumCPUs=1 NumTasks=1 CPUs/Task=1 ReqB:S:C:T=0:0:*:* # TRES=cpu=1,mem=100G,node=1,billing=1,gres/gpu=1 # Socks/Node=* NtasksPerN:B:S:C=0:0:*:* CoreSpec=* # MinCPUsNode=1 MinMemoryNode=100G MinTmpDiskNode=0 # Features=(null) DelayBoot=00:00:00 # OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null) # Command=/projects/mohimanilab/mustafa/tools/constrained-graph-variational-autoencoder/train_zinc.sh # WorkDir=/projects/mohimanilab/mustafa/tools/constrained-graph-variational-autoencoder # StdErr=/projects/mohimanilab/mustafa/tools/constrained-graph-variational-autoencoder/train_zinc.err # StdIn=/dev/null # StdOut=/projects/mohimanilab/mustafa/tools/constrained-graph-variational-autoencoder/train_zinc.out # Power= # TresPerNode=gpu:1 We have seem scontrol a few times now. It is generally used to display configuration information at various granularities (cluster-level, node-level, job-level). We have not seen sacct yet. It is used to show accounting data for jobs and their steps/task.\nExternal Resources      squeue man page scontrol man page sacct man page  "},{"id":30,"href":"/lane_custer/slurm-basics/submitting-jobs/sbatch-vs-srun/","title":"sbatch vs srun","parent":"Submitting Jobs","content":"These two commands take almost the exact same parameters. The difference is sbatch submits jobs to the Slurm scheduler, to be run when requested resources become available. Running the same job directly with srun will actually run synchronously. In other words, you will have to sit and wait while the job runs and logging out of the cluster will likely terminate your job. It is generally not recommended to directly execute jobs with srun, one exception can be see in Interactive Sessions\nExternal Resources      Useful distinction between srun and sbatch  "},{"id":31,"href":"/lane_custer/slurm-basics/transferring-data/scp/","title":"scp","parent":"Transferring Data","content":"The simplest way to transfer files is via scp. This functions similarly to cp, but operates over a network connection. It will respect your ssh configuration, so you can use Host definitions in the commands. For example, if you have set up the Lane ssh configuration entry as suggested you can do the following to download a file to your current local directory:\nscp lane:/PATH/TO/FILE . Uploading operates similarly.\nscp /PATH/TO/FILE lane:/PATH/TO/REMOTE/DESTINATION For directories use the -r flag to download/upload recursively. If possible, it\u0026rsquo;s suggested to compress files before transfer. To avoid relative path resolution, which could introduce errors, you can use readlink to get an absolute file path. For example:\nscp $(readlink -f ./RELATIVE/PATH) lane:/PATH/TO/REMOTE/DESTINATION For Windows machines see WinSCP.\nExternal Resources      scp Man Page WinSCP Site  "},{"id":32,"href":"/lane_custer/slurm-basics/","title":"Slurm Basics","parent":"Lane Cluster Documentation","content":"Defining Terms contains definitions of commonly used terms in this document.\nConnecting to Clusters contains information about how one can connect to both Lane and Bridges along with information about configuring your local ssh client.\nInteractive Sessions contains information about requesting and using interactive sessions instead of running things on the head node.\nExamining Partitions contains instructions on how to show information about partitions on a Slurm cluster and a description of existing partitions on Lane.\nSubmitting Jobs describes common sbatch and srun parameters with an extended example, how to design and use array jobs, and how to specify job dependencies.\nMonitoring Jobs describes how to list all existing jobs and get detailed information about particular jobs.\nStopping Jobs describes how to cancel jobs.\nIf you are already familiar with other cluster management software (Sun Grid Engine, PBS/Torque) you should still read Interactive Sessions. Otherwise you can refer to the cluster management rosetta stone.\n"},{"id":33,"href":"/lane_custer/tags/","title":"Tags","parent":"Lane Cluster Documentation","content":""}]